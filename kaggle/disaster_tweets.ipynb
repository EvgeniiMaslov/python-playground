{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nlp-getting-started.zip', 'sample_submission.csv', 'test.csv', 'train.csv']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'data',\n",
       " 'disaster_tweets.ipynb',\n",
       " 'get_dataset_from_kaggle.py']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(os.listdir('data'))\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7613.000000</td>\n",
       "      <td>7552</td>\n",
       "      <td>5080</td>\n",
       "      <td>7613</td>\n",
       "      <td>7613.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>221</td>\n",
       "      <td>3341</td>\n",
       "      <td>7503</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>fatalities</td>\n",
       "      <td>USA</td>\n",
       "      <td>11-Year-Old Boy Charged With Manslaughter of T...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>104</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5441.934848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.42966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3137.116090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.49506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2734.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5408.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8146.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10873.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id     keyword location  \\\n",
       "count    7613.000000        7552     5080   \n",
       "unique           NaN         221     3341   \n",
       "top              NaN  fatalities      USA   \n",
       "freq             NaN          45      104   \n",
       "mean     5441.934848         NaN      NaN   \n",
       "std      3137.116090         NaN      NaN   \n",
       "min         1.000000         NaN      NaN   \n",
       "25%      2734.000000         NaN      NaN   \n",
       "50%      5408.000000         NaN      NaN   \n",
       "75%      8146.000000         NaN      NaN   \n",
       "max     10873.000000         NaN      NaN   \n",
       "\n",
       "                                                     text      target  \n",
       "count                                                7613  7613.00000  \n",
       "unique                                               7503         NaN  \n",
       "top     11-Year-Old Boy Charged With Manslaughter of T...         NaN  \n",
       "freq                                                   10         NaN  \n",
       "mean                                                  NaN     0.42966  \n",
       "std                                                   NaN     0.49506  \n",
       "min                                                   NaN     0.00000  \n",
       "25%                                                   NaN     0.00000  \n",
       "50%                                                   NaN     0.00000  \n",
       "75%                                                   NaN     1.00000  \n",
       "max                                                   NaN     1.00000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'ablaze', 'accident', 'aftershock', 'airplane%20accident',\n",
       "       'ambulance', 'annihilated', 'annihilation', 'apocalypse',\n",
       "       'armageddon', 'army', 'arson', 'arsonist', 'attack', 'attacked',\n",
       "       'avalanche', 'battle', 'bioterror', 'bioterrorism', 'blaze',\n",
       "       'blazing', 'bleeding', 'blew%20up', 'blight', 'blizzard', 'blood',\n",
       "       'bloody', 'blown%20up', 'body%20bag', 'body%20bagging',\n",
       "       'body%20bags', 'bomb', 'bombed', 'bombing', 'bridge%20collapse',\n",
       "       'buildings%20burning', 'buildings%20on%20fire', 'burned',\n",
       "       'burning', 'burning%20buildings', 'bush%20fires', 'casualties',\n",
       "       'casualty', 'catastrophe', 'catastrophic', 'chemical%20emergency',\n",
       "       'cliff%20fall', 'collapse', 'collapsed', 'collide', 'collided',\n",
       "       'collision', 'crash', 'crashed', 'crush', 'crushed', 'curfew',\n",
       "       'cyclone', 'damage', 'danger', 'dead', 'death', 'deaths', 'debris',\n",
       "       'deluge', 'deluged', 'demolish', 'demolished', 'demolition',\n",
       "       'derail', 'derailed', 'derailment', 'desolate', 'desolation',\n",
       "       'destroy', 'destroyed', 'destruction', 'detonate', 'detonation',\n",
       "       'devastated', 'devastation', 'disaster', 'displaced', 'drought',\n",
       "       'drown', 'drowned', 'drowning', 'dust%20storm', 'earthquake',\n",
       "       'electrocute', 'electrocuted', 'emergency', 'emergency%20plan',\n",
       "       'emergency%20services', 'engulfed', 'epicentre', 'evacuate',\n",
       "       'evacuated', 'evacuation', 'explode', 'exploded', 'explosion',\n",
       "       'eyewitness', 'famine', 'fatal', 'fatalities', 'fatality', 'fear',\n",
       "       'fire', 'fire%20truck', 'first%20responders', 'flames',\n",
       "       'flattened', 'flood', 'flooding', 'floods', 'forest%20fire',\n",
       "       'forest%20fires', 'hail', 'hailstorm', 'harm', 'hazard',\n",
       "       'hazardous', 'heat%20wave', 'hellfire', 'hijack', 'hijacker',\n",
       "       'hijacking', 'hostage', 'hostages', 'hurricane', 'injured',\n",
       "       'injuries', 'injury', 'inundated', 'inundation', 'landslide',\n",
       "       'lava', 'lightning', 'loud%20bang', 'mass%20murder',\n",
       "       'mass%20murderer', 'massacre', 'mayhem', 'meltdown', 'military',\n",
       "       'mudslide', 'natural%20disaster', 'nuclear%20disaster',\n",
       "       'nuclear%20reactor', 'obliterate', 'obliterated', 'obliteration',\n",
       "       'oil%20spill', 'outbreak', 'pandemonium', 'panic', 'panicking',\n",
       "       'police', 'quarantine', 'quarantined', 'radiation%20emergency',\n",
       "       'rainstorm', 'razed', 'refugees', 'rescue', 'rescued', 'rescuers',\n",
       "       'riot', 'rioting', 'rubble', 'ruin', 'sandstorm', 'screamed',\n",
       "       'screaming', 'screams', 'seismic', 'sinkhole', 'sinking', 'siren',\n",
       "       'sirens', 'smoke', 'snowstorm', 'storm', 'stretcher',\n",
       "       'structural%20failure', 'suicide%20bomb', 'suicide%20bomber',\n",
       "       'suicide%20bombing', 'sunk', 'survive', 'survived', 'survivors',\n",
       "       'terrorism', 'terrorist', 'threat', 'thunder', 'thunderstorm',\n",
       "       'tornado', 'tragedy', 'trapped', 'trauma', 'traumatised',\n",
       "       'trouble', 'tsunami', 'twister', 'typhoon', 'upheaval',\n",
       "       'violent%20storm', 'volcano', 'war%20zone', 'weapon', 'weapons',\n",
       "       'whirlwind', 'wild%20fires', 'wildfire', 'windstorm', 'wounded',\n",
       "       'wounds', 'wreck', 'wreckage', 'wrecked'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.keyword.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sqrte\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r'\\d+', '', sentence)\n",
    "    sentence = sentence.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "    sentence = word_tokenize(sentence)\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    sentence = [word for word in sentence if word not in stop_words]\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    sentence = [stemmer.stem(word) for word in sentence]\n",
    "    \n",
    "    # lemmatizer = WordNetLemmatizer()\n",
    "    # sentence = [lemmatizer.lemmatize(word) for word in sentence]\n",
    "    return ' '.join(sentence)\n",
    "    \n",
    "\n",
    "train_prep = train.copy()\n",
    "train_prep['text'] = train_prep['text'].apply(text_preprocess)\n",
    "train_prep.replace(np.nan, 'notspecified', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               deed reason earthquak may allah forgiv us\n",
       "1                    forest fire near la rong sask canada\n",
       "2       resid ask shelter place notifi offic evacu she...\n",
       "3             peopl receiv wildfir evacu order california\n",
       "4       got sent photo rubi alaska smoke wildfir pour ...\n",
       "                              ...                        \n",
       "7608    two giant crane hold bridg collaps nearbi home...\n",
       "7609    ariaahrari thetawniest control wild fire calif...\n",
       "7610                utckm volcano hawaii httptcozdtoydebj\n",
       "7611    polic investig ebik collid car littl portug eb...\n",
       "7612    latest home raze northern california wildfir a...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prep.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 1000\n",
    "vectorizer = CountVectorizer(max_features=n_features)\n",
    "X = vectorizer.fit_transform(train_prep.text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(train_prep.text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([X, pd.get_dummies(train_prep[['keyword', 'location']])])\n",
    "y = train_prep.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tagged_document(list_of_list_of_words):\n",
    "    for i, list_of_words in enumerate(list_of_list_of_words):\n",
    "        yield gensim.models.doc2vec.TaggedDocument(list_of_words, [i])\n",
    "        \n",
    "train_data = list(create_tagged_document(train_prep))\n",
    "\n",
    "# Init the Doc2Vec model\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "# Build the Volabulary\n",
    "model.build_vocab(train_data)\n",
    "# Train the Doc2Vec model\n",
    "model.train(train_data, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2vec(sentence):\n",
    "    sentence = sentence.split(' ')\n",
    "    vec = model.infer_vector(sentence)\n",
    "    return vec\n",
    "\n",
    "t = train_prep['text'].apply(sent2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [0.008554739, 0.008918406, 0.00113351, 0.00547...\n",
       "1       [-0.007037535, -0.0066475165, -0.005103788, 0....\n",
       "2       [-0.0034955828, -0.006101159, -0.00051764265, ...\n",
       "3       [0.005369737, -8.416798e-05, 0.0019173216, 0.0...\n",
       "4       [0.0018455514, 0.0069972407, -0.0051825983, -0...\n",
       "                              ...                        \n",
       "7608    [-0.009516171, 0.008940686, 0.003917992, -0.00...\n",
       "7609    [0.0036270337, -0.004818424, 0.0013614105, -0....\n",
       "7610    [0.008374924, -0.0030101107, 0.0048486115, -0....\n",
       "7611    [-0.0084608635, -0.003890377, 0.0019195833, 0....\n",
       "7612    [-0.0030570908, -0.009407557, 0.0037999274, 0....\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sqrte\\anaconda3\\envs\\ml_base\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-c998b576c1d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sqrte\\anaconda3\\envs\\ml_base\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    717\u001b[0m             \u001b[0mevals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_features_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(t, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array([-9.2963278e-03,  7.0536546e-03, -1.9054184e-03, -3.5246655e-03,\n",
       "        3.5808985e-03,  1.8847714e-03,  5.6802719e-03, -2.8058714e-03,\n",
       "        8.7723834e-03, -4.9404348e-03, -1.7816613e-03, -3.5676758e-03,\n",
       "       -7.6963012e-03,  2.8734813e-03, -8.9858808e-03,  7.9818284e-03,\n",
       "       -6.2274914e-03,  8.1235380e-04,  6.9958814e-03, -4.1256733e-03,\n",
       "       -5.9249122e-03, -9.5416950e-03, -2.3893090e-03,  9.0189949e-03,\n",
       "       -8.0283983e-03, -8.9227819e-05, -2.7838359e-03,  8.6536100e-03,\n",
       "        9.9012395e-03,  3.2648473e-05, -5.3528822e-03, -7.9186969e-03,\n",
       "       -9.2713432e-03,  2.9375460e-03,  3.3426567e-03,  3.1763371e-03,\n",
       "       -2.0706092e-03, -5.6415698e-03, -2.3462554e-03, -5.6773592e-03,\n",
       "       -8.8509284e-03, -1.6691546e-03,  7.0873299e-03,  5.6847911e-03,\n",
       "       -9.3508046e-03, -3.3446113e-03,  5.5040186e-03, -4.4696635e-04,\n",
       "        7.1080229e-03,  2.3768949e-03], dtype=float32)],\n",
       "       [array([ 0.00874881,  0.00989354, -0.00822412, -0.00523411,  0.00139255,\n",
       "        0.00927229,  0.00631194,  0.00303381, -0.00545552,  0.00165847,\n",
       "       -0.00955468, -0.00721984, -0.00057869, -0.00641637,  0.0082728 ,\n",
       "        0.00535565, -0.00258276, -0.00435118,  0.00513381,  0.00809278,\n",
       "        0.00252536, -0.00315351, -0.00767331,  0.00099437,  0.0040763 ,\n",
       "        0.00543292, -0.00909204,  0.00894739, -0.00045681,  0.00670988,\n",
       "        0.00481354,  0.0046018 , -0.00178778,  0.00570055, -0.00625294,\n",
       "        0.00992934, -0.00829195, -0.00230309, -0.00021778, -0.00135745,\n",
       "       -0.0017475 ,  0.00710414, -0.00680321, -0.00455533,  0.00572159,\n",
       "       -0.00873152,  0.00823228, -0.00569364,  0.0090311 , -0.00375555],\n",
       "      dtype=float32)],\n",
       "       [array([-3.3598579e-04, -9.1932602e-03, -7.3166164e-03, -6.8417881e-03,\n",
       "       -2.0323871e-03, -5.4053357e-03,  7.2304681e-03, -1.2317634e-03,\n",
       "       -3.0073721e-03,  7.3475074e-03, -6.4492892e-03, -8.1239650e-03,\n",
       "       -4.4838522e-04,  1.8964760e-03, -6.5097533e-04, -9.2573045e-03,\n",
       "        4.2902450e-03, -5.7685552e-03, -8.6040469e-03,  3.8341757e-05,\n",
       "        4.5200665e-03,  2.9983770e-04, -6.0050027e-03,  2.0714677e-03,\n",
       "        9.9327434e-03,  3.0286913e-03,  2.3206649e-03, -9.9761626e-03,\n",
       "       -7.9491725e-03, -9.5299361e-03, -2.8972731e-03, -4.4641043e-03,\n",
       "        7.3513887e-03, -2.2468506e-03, -1.3725772e-03,  4.0031369e-03,\n",
       "       -1.7357630e-03,  2.9432380e-03, -8.6659726e-05,  5.8858059e-03,\n",
       "        8.1033837e-03,  5.2935765e-03,  5.7956153e-03, -9.7800875e-03,\n",
       "       -6.6139884e-03,  9.2232395e-03,  6.1362730e-03,  1.7196799e-03,\n",
       "        3.9243107e-03,  9.7123830e-04], dtype=float32)],\n",
       "       ...,\n",
       "       [array([-0.00073752, -0.00720249,  0.00488969,  0.00483778,  0.00975634,\n",
       "        0.00967351,  0.00789613,  0.00171853, -0.00439511, -0.00176596,\n",
       "       -0.00120365,  0.00762391,  0.00066095, -0.00111959, -0.00695378,\n",
       "        0.00570709,  0.00350256, -0.00152538, -0.00579043,  0.00816162,\n",
       "       -0.0025466 , -0.00702243,  0.00343418, -0.00845709, -0.00118623,\n",
       "       -0.00290817, -0.00580021,  0.00871781,  0.00674882, -0.00742995,\n",
       "        0.00977965, -0.00636277,  0.00814139,  0.00406511, -0.00173857,\n",
       "        0.00800729, -0.00138576,  0.00790628, -0.00761629, -0.00254991,\n",
       "        0.00096815, -0.00624056,  0.00150975,  0.00266791,  0.00769054,\n",
       "       -0.00508088,  0.0014648 ,  0.00323307,  0.00719838, -0.00664636],\n",
       "      dtype=float32)],\n",
       "       [array([-7.9865027e-03,  2.4724703e-03,  6.0904822e-03,  2.4244825e-03,\n",
       "       -9.5348386e-03,  1.8439314e-03, -3.6591326e-03,  5.4194639e-03,\n",
       "        6.8836757e-03, -8.9677935e-03,  1.9737545e-03, -5.6849523e-03,\n",
       "        1.4004197e-03, -5.5818232e-03,  9.4493246e-03, -7.0061265e-03,\n",
       "        5.8068740e-03,  2.6420534e-03,  9.6985502e-03,  3.9058321e-04,\n",
       "        2.9561978e-03, -8.4152427e-03, -2.6105393e-03, -7.2032548e-03,\n",
       "        9.4705187e-03, -1.0896089e-03, -6.0995538e-03,  4.9414234e-03,\n",
       "       -4.3613408e-03, -7.8725192e-05, -9.2412941e-03,  1.2071525e-04,\n",
       "        6.9760056e-03,  3.5175614e-03,  4.7283513e-03, -2.5184341e-03,\n",
       "       -4.9225218e-04, -4.3623853e-03,  7.1755424e-03,  3.1802219e-03,\n",
       "        6.6350973e-03,  6.9914726e-03, -4.2451466e-03,  2.7316939e-03,\n",
       "       -8.9009348e-03,  6.0991701e-03,  4.7864425e-03, -7.5640623e-03,\n",
       "       -2.6672424e-03,  2.6347552e-04], dtype=float32)],\n",
       "       [array([-7.2567756e-03,  9.4202571e-03, -1.8522426e-03,  9.5931897e-03,\n",
       "       -3.7499887e-03,  4.4416455e-03,  8.8957157e-03,  3.2473907e-03,\n",
       "       -4.9012876e-03, -2.9635341e-03,  6.3260426e-03, -2.1075315e-03,\n",
       "        8.7083755e-03, -8.7331692e-03,  5.7371999e-03,  3.1594790e-03,\n",
       "        2.4489784e-03, -9.7809071e-03,  8.8664368e-03,  9.6734129e-03,\n",
       "       -4.8677744e-03,  2.3840545e-03,  4.5574531e-03, -6.9454573e-03,\n",
       "       -8.6089047e-03, -4.5490190e-03,  8.0127642e-03, -1.1596133e-03,\n",
       "       -6.1228299e-03, -6.8287747e-03, -7.9092020e-03, -1.6636719e-03,\n",
       "        3.1707119e-03,  3.7811657e-03,  1.8005373e-03,  7.2042854e-03,\n",
       "        4.9522961e-03, -1.9228910e-03,  1.8812484e-03,  2.3326136e-03,\n",
       "       -9.1271726e-03,  2.2457473e-04, -2.3093896e-06, -5.1131477e-03,\n",
       "        2.7940448e-03,  9.2748841e-03, -1.8457554e-03, -1.8237716e-03,\n",
       "        1.7105670e-03, -1.6808856e-03], dtype=float32)]], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6217008797653959"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "7608    1\n",
       "7609    1\n",
       "7610    1\n",
       "7611    1\n",
       "7612    1\n",
       "Name: target, Length: 7613, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
