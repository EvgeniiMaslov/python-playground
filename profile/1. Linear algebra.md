

## Linear Algebra



### Eigen decomposition

$$
\bold A \bold v = \lambda \bold v
$$

\lambda = eigenvalue, **v** - eigenvector. We can form a matrix **V** by concatenating vectors **v** with one vector per column. Likewise, we can concatenate the eigenvalues to form a vector **λ**. The eigendecomposition of **A** is given by:
$$
\bold A = \bold V diag(\bold λ) \bold V^{-1}
$$
Every real symmetric matrix can be decomposed into an expression using only real-valued eigenvectors and eigenvalues:
$$
\bold A = \bold Q \bold Λ \bold Q^T
$$
Where **Q** - orthogonal matrix composed of eigenvectors of **A**, and **Λ** is a diagonal matrix, Λ_i,i is associated with eigenvector in column i of **Q**, denoted as **Q**_:,i

Ортогона́льная ма́трица — квадратная матрица с вещественными  элементами, результат умножения которой на транспонированную матрицу  равен единичной матрице: или, что эквивалентно, её обратная матрица равна транспонированной  матрице.



### Singular Value Decomposition



Every real matrix has a SVD, but the same is not true of the eigen decomposition. The SVD is similar to eigen decomposition, except A is the product of three matrices:
$$
\bold A = \bold U \bold D \bold V^T
$$
**U** and **V** - orthogonal matrices, **D** - diagonal. The elements along the diagonal of **D** are known as the singular values of matrix **A**. The columns of **U** - left-singular vectors; the columns of **V** - right-singular vectors.

We can interpret SVD in terms of eigen decomposition of **A**. The left-singular vectors of **A** are the eigenvectors of **A**^T; the right-singular vectors are the eigenvectors **A**^T **A**. The non-zero singular values of **A** are the square root of eigenvalues of **A**^T **A**.

U: u_j - собственные векторы матрицы A * A^T

V: v_j - собственные векторы матрицы A^T * A

D: на диагонали - корни из собственных значений матриц A^T * A и  A * A^T









## 