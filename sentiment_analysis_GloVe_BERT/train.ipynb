{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "522d283981f1463882b103b92049c257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9fbd28f0c0e44337bd390455eb41b14f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_710d046be7ec481fb911e2747740c34d",
              "IPY_MODEL_1777630faa88474295f1791067fcb6ad"
            ]
          }
        },
        "9fbd28f0c0e44337bd390455eb41b14f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "710d046be7ec481fb911e2747740c34d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_28d4bdab5e8e400da5c4d778bb39b42d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_561460f0d4844f4b922ed36ffe7be18e"
          }
        },
        "1777630faa88474295f1791067fcb6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_33cdc90a766e422cabbae354d3bedb9a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [01:01&lt;00:00, 6.99B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_760b0ec54ef740b89f57509c3d77d67b"
          }
        },
        "28d4bdab5e8e400da5c4d778bb39b42d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "561460f0d4844f4b922ed36ffe7be18e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33cdc90a766e422cabbae354d3bedb9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "760b0ec54ef740b89f57509c3d77d67b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a57d40ac6132426098fa7c3e3520a116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1a01c11f43674e6fa6855407f161f32b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_714e0ebbdf444d18bca0d84c9cb1eb5c",
              "IPY_MODEL_21b7621129b04be888b77c2048b99cfd"
            ]
          }
        },
        "1a01c11f43674e6fa6855407f161f32b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "714e0ebbdf444d18bca0d84c9cb1eb5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1577d8ad3ba641c4b25cd37de65fe17a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 526681800,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 526681800,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_788ff2026e894eb3916e867352d87e8b"
          }
        },
        "21b7621129b04be888b77c2048b99cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_69f7188f64f24036bddf6b96a385fe8e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 527M/527M [00:10&lt;00:00, 49.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_96b5c3088b8b41168d84d2091ac79f77"
          }
        },
        "1577d8ad3ba641c4b25cd37de65fe17a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "788ff2026e894eb3916e867352d87e8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69f7188f64f24036bddf6b96a385fe8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "96b5c3088b8b41168d84d2091ac79f77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecological-italic"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import os"
      ],
      "id": "ecological-italic",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uniform-memorial",
        "outputId": "293b2805-7c55-47a2-993e-2ca51b1ed71d"
      },
      "source": [
        "imdb_train, ds_info = tfds.load(name=\"imdb_reviews\",\n",
        "                                split=\"train\",\n",
        "                                with_info=True, as_supervised=True)\n",
        "\n",
        "imdb_test = tfds.load(name=\"imdb_reviews\", split=\"test\", as_supervised=True)"
      ],
      "id": "uniform-memorial",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train, from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split test, from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "civic-america"
      },
      "source": [
        "### Keras Tokenizer"
      ],
      "id": "civic-america"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy1G5asKUXkp"
      },
      "source": [
        "X_train = list(map(lambda x: x[0].numpy().decode('utf-8'), imdb_train))\n",
        "y_train = list(map(lambda x: x[1], imdb_train))"
      ],
      "id": "Qy1G5asKUXkp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reflected-studio",
        "outputId": "7aa21b2a-d2a0-4bce-983b-7f58605aa06a"
      },
      "source": [
        "%%time\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "                                                  lower=True,\n",
        "                                                  split=\" \",)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_encoded = tokenizer.texts_to_sequences(X_train)\n",
        "X_encoded = pad_sequences(X_encoded, padding=\"post\", maxlen=150) "
      ],
      "id": "reflected-studio",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wall time: 9.88 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chief-equipment"
      },
      "source": [
        "### TFDS Tokenizer"
      ],
      "id": "chief-equipment"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suburban-characterization",
        "outputId": "c739aac6-e6af-4934-c3a6-d166a64958af"
      },
      "source": [
        "tokenizer_tfds = tfds.deprecated.text.Tokenizer()\n",
        "vocabulary_set = set()\n",
        "MAX_TOKENS = 0\n",
        "for example, label in imdb_train:\n",
        "    some_tokens = tokenizer_tfds.tokenize(example.numpy())\n",
        "    if MAX_TOKENS < len(some_tokens):\n",
        "        MAX_TOKENS = len(some_tokens)\n",
        "    vocabulary_set.update(some_tokens)\n",
        "    \n",
        "imdb_encoder = tfds.deprecated.text.TokenTextEncoder(vocabulary_set, lowercase=True, tokenizer=tokenizer_tfds)\n",
        "\n",
        "vocab_size = imdb_encoder.vocab_size\n",
        "print(vocab_size, MAX_TOKENS)"
      ],
      "id": "suburban-characterization",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93931 2525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chubby-china"
      },
      "source": [
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "def encode_pad_transform(sample):\n",
        "    \n",
        "    encoded = imdb_encoder.encode(sample.numpy())\n",
        "    pad = sequence.pad_sequences([encoded], padding='post',maxlen=150)\n",
        "    return np.array(pad[0], dtype=np.int64)\n",
        "\n",
        "def encode_tf_fn(sample, label):\n",
        "    \n",
        "    encoded = tf.py_function(encode_pad_transform,\n",
        "                             inp=[sample],\n",
        "                             Tout=(tf.int64))\n",
        "    \n",
        "    encoded.set_shape([None])\n",
        "    label.set_shape([])\n",
        "    return encoded, label "
      ],
      "id": "chubby-china",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "intense-python"
      },
      "source": [
        "encoded_train = imdb_train.map(encode_tf_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "encoded_test = imdb_test.map(encode_tf_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "id": "intense-python",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "provincial-powder"
      },
      "source": [
        "### Loading pre-trained GloVe embeddings"
      ],
      "id": "provincial-powder"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "super-forge"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "id": "super-forge",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0RAY0a5Uu-y",
        "outputId": "61aed018-9dd6-47d5-e63f-c8c02582a476"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('drive')\n",
        "glove_path = 'drive/MyDrive/GloVe/glove.6B.50d.txt'"
      ],
      "id": "N0RAY0a5Uu-y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crude-zoning",
        "outputId": "0cfd2c91-763b-489b-c8b0-702649dbe042"
      },
      "source": [
        "dict_w2v = {}\n",
        "with open(glove_path, \"rb\") as file:\n",
        "    for line in file:\n",
        "        tokens = line.split()\n",
        "        word = tokens[0].decode('utf-8')\n",
        "        vector = np.array(tokens[1:], dtype=np.float32)\n",
        "        \n",
        "        if vector.shape[0] == 50:\n",
        "            dict_w2v[word] = vector\n",
        "        else:\n",
        "            print(\"There was an issue with \" + word)\n",
        "            \n",
        "# let's check the vocabulary size\n",
        "print(\"Dictionary Size: \", len(dict_w2v))"
      ],
      "id": "crude-zoning",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dictionary Size:  400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tutorial-haven"
      },
      "source": [
        "vocab_size = imdb_encoder.vocab_size\n",
        "embedding_dim = 50\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))"
      ],
      "id": "tutorial-haven",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geological-wings"
      },
      "source": [
        "### Tfds"
      ],
      "id": "geological-wings"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "descending-wallace",
        "outputId": "fe378c94-ef72-4908-a106-711305293bec"
      },
      "source": [
        "unk_cnt = 0\n",
        "unk_set = set()\n",
        "for word in imdb_encoder.tokens:\n",
        "    embedding_vector = dict_w2v.get(word)\n",
        "    \n",
        "    if embedding_vector is not None:\n",
        "        tkn_id = imdb_encoder.encode(word)[0]\n",
        "        embedding_matrix[tkn_id] = embedding_vector\n",
        "    else:\n",
        "        unk_cnt += 1\n",
        "        unk_set.add(word)\n",
        "# Print how many weren't found\n",
        "print(\"Total unknown words: \", unk_cnt)"
      ],
      "id": "descending-wallace",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total unknown words:  14553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hairy-balance"
      },
      "source": [
        "### Keras"
      ],
      "id": "hairy-balance"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "choice-dream",
        "outputId": "537c8465-1094-4ead-e54a-f6d2c213ebdb"
      },
      "source": [
        "unk_cnt = 0\n",
        "unk_set = set()\n",
        "for word in list(tokenizer.word_index.keys()):\n",
        "    embedding_vector = dict_w2v.get(word)\n",
        "    \n",
        "    if embedding_vector is not None:\n",
        "        tkn_id = tokenizer.word_index[word]\n",
        "        embedding_matrix[tkn_id] = embedding_vector\n",
        "    else:\n",
        "        unk_cnt += 1\n",
        "        unk_set.add(word)\n",
        "# Print how many weren't found\n",
        "print(\"Total unknown words: \", unk_cnt)"
      ],
      "id": "choice-dream",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total unknown words:  28423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "answering-temple"
      },
      "source": [
        "### Build model"
      ],
      "id": "answering-temple"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liked-engagement"
      },
      "source": [
        "vocab_size = imdb_encoder.vocab_size # len(chars)\n",
        "# Number of RNN units\n",
        "rnn_units = 64\n",
        "#batch size\n",
        "BATCH_SIZE=100"
      ],
      "id": "liked-engagement",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "silent-forum"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense\n",
        "\n",
        "def build_model_bilstm(vocab_size, embedding_dim, rnn_units, batch_size, train_emb=False):\n",
        "    model = tf.keras.Sequential([\n",
        "        Embedding(vocab_size, embedding_dim, mask_zero=True,\n",
        "                  weights=[embedding_matrix], trainable=train_emb),\n",
        "        Bidirectional(LSTM(rnn_units, return_sequences=True,\n",
        "                           dropout=0.5)),\n",
        "        Bidirectional(LSTM(rnn_units, dropout=0.25)),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model"
      ],
      "id": "silent-forum",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cultural-behalf",
        "outputId": "db1d8ea9-aa2f-4527-e519-e218a66f06a0"
      },
      "source": [
        "model_fe = build_model_bilstm(\n",
        "    vocab_size = vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE)\n",
        "model_fe.summary()"
      ],
      "id": "cultural-behalf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 50)          4696550   \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, None, 128)         58880     \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 4,854,375\n",
            "Trainable params: 157,825\n",
            "Non-trainable params: 4,696,550\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "senior-electronics"
      },
      "source": [
        "model_fe.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'Precision', 'Recall'])"
      ],
      "id": "senior-electronics",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "canadian-glossary",
        "outputId": "33d6336a-19cd-42f8-a562-f92813a996d9"
      },
      "source": [
        "encoded_train_batched = encoded_train.batch(BATCH_SIZE).prefetch(100)\n",
        "model_fe.fit(encoded_train_batched, epochs=10)"
      ],
      "id": "canadian-glossary",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - 33s 82ms/step - loss: 0.6347 - accuracy: 0.6282 - precision: 0.6288 - recall: 0.6348\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 22s 90ms/step - loss: 0.5586 - accuracy: 0.7157 - precision: 0.7223 - recall: 0.7025\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 23s 90ms/step - loss: 0.5194 - accuracy: 0.7432 - precision: 0.7470 - recall: 0.7379\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 22s 90ms/step - loss: 0.4896 - accuracy: 0.7647 - precision: 0.7644 - recall: 0.7665\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 23s 90ms/step - loss: 0.5145 - accuracy: 0.7462 - precision: 0.7491 - recall: 0.7424\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 22s 90ms/step - loss: 0.4608 - accuracy: 0.7800 - precision: 0.7829 - recall: 0.7757\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 23s 91ms/step - loss: 0.4534 - accuracy: 0.7883 - precision: 0.7968 - recall: 0.7752\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 23s 90ms/step - loss: 0.4411 - accuracy: 0.7967 - precision: 0.7993 - recall: 0.7930\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 23s 90ms/step - loss: 0.4346 - accuracy: 0.7933 - precision: 0.7908 - recall: 0.7991\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 23s 90ms/step - loss: 0.4204 - accuracy: 0.8052 - precision: 0.8070 - recall: 0.8032\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0c8343bdd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9771gUeVVoP"
      },
      "source": [
        "### Fine-tuning"
      ],
      "id": "U9771gUeVVoP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opposite-episode",
        "outputId": "0d1583f7-ff9f-437e-e851-46d9cf5a2378"
      },
      "source": [
        "model_ft = build_model_bilstm(\n",
        " vocab_size=vocab_size,\n",
        " embedding_dim=embedding_dim,\n",
        " rnn_units=rnn_units,\n",
        " batch_size=BATCH_SIZE,\n",
        " train_emb=True)\n",
        "model_ft.summary()"
      ],
      "id": "opposite-episode",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, None, 50)          4696550   \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, None, 128)         58880     \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 4,854,375\n",
            "Trainable params: 4,854,375\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfiHLm6nVZoO",
        "outputId": "b86bf691-dcb4-4376-85c3-5052dd37e824"
      },
      "source": [
        "model_ft.compile(loss='binary_crossentropy',\n",
        " optimizer='adam',\n",
        " metrics=['accuracy', 'Precision', 'Recall'])\n",
        "model_ft.fit(encoded_train_batched, epochs=10)"
      ],
      "id": "dfiHLm6nVZoO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - 44s 125ms/step - loss: 0.6129 - accuracy: 0.6483 - precision: 0.6497 - recall: 0.6520\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 33s 131ms/step - loss: 0.4159 - accuracy: 0.8108 - precision: 0.8106 - recall: 0.8120\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 33s 131ms/step - loss: 0.3367 - accuracy: 0.8522 - precision: 0.8549 - recall: 0.8491\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 33s 130ms/step - loss: 0.2909 - accuracy: 0.8764 - precision: 0.8749 - recall: 0.8789\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 33s 131ms/step - loss: 0.2436 - accuracy: 0.9008 - precision: 0.9008 - recall: 0.9011\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 33s 131ms/step - loss: 0.2209 - accuracy: 0.9113 - precision: 0.9097 - recall: 0.9135\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 33s 131ms/step - loss: 0.1858 - accuracy: 0.9259 - precision: 0.9270 - recall: 0.9250\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 33s 131ms/step - loss: 0.1679 - accuracy: 0.9377 - precision: 0.9371 - recall: 0.9387\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 33s 131ms/step - loss: 0.1424 - accuracy: 0.9458 - precision: 0.9443 - recall: 0.9477\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 33s 131ms/step - loss: 0.1214 - accuracy: 0.9557 - precision: 0.9526 - recall: 0.9593\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0c8343bfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiyMUAkPVfcn"
      },
      "source": [
        "### BERT"
      ],
      "id": "IiyMUAkPVfcn"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN8CyksIVe6B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70eb35e5-4654-4f85-86cc-2560b776e390"
      },
      "source": [
        "!pip install transformers==3.0.2"
      ],
      "id": "fN8CyksIVe6B",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==3.0.2 in /usr/local/lib/python3.7/dist-packages (3.0.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.1.95)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.8.1rc1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.0.45)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (8.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcWGa_OWVhfX"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "bert_name = 'bert-base-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_name,\n",
        "                                          add_special_tokens=True,\n",
        "                                          do_lower_case=False,\n",
        "                                          max_length=150,\n",
        "                                          pad_to_max_length=True)"
      ],
      "id": "wcWGa_OWVhfX",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVF2L7zFVhcE"
      },
      "source": [
        "def bert_encoder(review):\n",
        " txt = review.numpy().decode('utf-8')\n",
        " encoded = tokenizer.encode_plus(txt, add_special_tokens=True,\n",
        "                                 max_length=150,\n",
        "                                 pad_to_max_length=True,\n",
        "                                 return_attention_mask=True,\n",
        "                                 truncation=True,\n",
        "                                 return_token_type_ids=True)\n",
        " \n",
        " return encoded['input_ids'], encoded['token_type_ids'], encoded['attention_mask']"
      ],
      "id": "fVF2L7zFVhcE",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwzIb8kfVhV6"
      },
      "source": [
        "bert_train = [bert_encoder(r) for r, l in imdb_train]\n",
        "bert_lbl = [l for r, l in imdb_train]\n",
        "bert_train = np.array(bert_train)\n",
        "bert_lbl = tf.keras.utils.to_categorical(bert_lbl, num_classes=2)"
      ],
      "id": "XwzIb8kfVhV6",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xavyh0VRaaFX",
        "outputId": "ee1b7dee-cdde-4062-d31d-dba9763f2dc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(bert_train,\n",
        "                                                  bert_lbl,\n",
        "                                                  test_size=0.2,\n",
        "                                                  random_state=42)\n",
        "\n",
        "print(x_train.shape, y_train.shape)"
      ],
      "id": "Xavyh0VRaaFX",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 3, 150) (20000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tcivOyAZ8SA"
      },
      "source": [
        "tr_reviews, tr_segments, tr_masks = np.split(x_train, 3, axis=1)\n",
        "val_reviews, val_segments, val_masks = np.split(x_val, 3, axis=1)\n",
        "\n",
        "tr_reviews = tr_reviews.squeeze()\n",
        "tr_segments = tr_segments.squeeze()\n",
        "tr_masks = tr_masks.squeeze()\n",
        "\n",
        "val_reviews = val_reviews.squeeze()\n",
        "val_segments = val_segments.squeeze()\n",
        "val_masks = val_masks.squeeze()"
      ],
      "id": "7tcivOyAZ8SA",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr4X1WsEaGE9"
      },
      "source": [
        "def example_to_features(input_ids,attention_masks,token_type_ids,y):\n",
        " return {\"input_ids\": input_ids,\n",
        "         \"attention_mask\": attention_masks,\n",
        "         \"token_type_ids\": token_type_ids},y"
      ],
      "id": "qr4X1WsEaGE9",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKmINBUOaGB6"
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((tr_reviews,\n",
        "                                               tr_masks, tr_segments, y_train)).map(example_to_features).shuffle(100).batch(16)\n",
        "\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices((val_reviews,\n",
        "                                               val_masks, val_segments, y_val)).map(example_to_features).shuffle(100).batch(16)"
      ],
      "id": "mKmINBUOaGB6",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1wXY-HoaF9w",
        "outputId": "6a0cf7da-9db6-42a7-9c5d-e475804f8bbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218,
          "referenced_widgets": [
            "522d283981f1463882b103b92049c257",
            "9fbd28f0c0e44337bd390455eb41b14f",
            "710d046be7ec481fb911e2747740c34d",
            "1777630faa88474295f1791067fcb6ad",
            "28d4bdab5e8e400da5c4d778bb39b42d",
            "561460f0d4844f4b922ed36ffe7be18e",
            "33cdc90a766e422cabbae354d3bedb9a",
            "760b0ec54ef740b89f57509c3d77d67b",
            "a57d40ac6132426098fa7c3e3520a116",
            "1a01c11f43674e6fa6855407f161f32b",
            "714e0ebbdf444d18bca0d84c9cb1eb5c",
            "21b7621129b04be888b77c2048b99cfd",
            "1577d8ad3ba641c4b25cd37de65fe17a",
            "788ff2026e894eb3916e867352d87e8b",
            "69f7188f64f24036bddf6b96a385fe8e",
            "96b5c3088b8b41168d84d2091ac79f77"
          ]
        }
      },
      "source": [
        "from transformers import TFBertForSequenceClassification\n",
        "\n",
        "bert_model = TFBertForSequenceClassification.from_pretrained(bert_name)"
      ],
      "id": "N1wXY-HoaF9w",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "522d283981f1463882b103b92049c257",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a57d40ac6132426098fa7c3e3520a116",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=526681800.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_tf_utils:Some weights of the model checkpoint at bert-base-cased were not used when initializing TFBertForSequenceClassification: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_tf_utils:Some weights of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier', 'dropout_37']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci5ks4rlsngb",
        "outputId": "54b43ebb-628c-4a92-e55d-914429d6c99a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!saved_model_cli show --dir {export_path} --all"
      ],
      "id": "Ci5ks4rlsngb",
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['input_ids'] tensor_info:\n",
            "        dtype: DT_INT32\n",
            "        shape: (-1, 5)\n",
            "        name: serving_default_input_ids:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['output_1'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 2)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0521 11:32:38.297619 140153549420416 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "\n",
            "Defined Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: dict\n",
            "          Value: {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name=u'inputs/input_ids'), \b\b}\n",
            "        Argument #2\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #4\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #5\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #6\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #7\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #8\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #9\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #10\n",
            "          DType: bool\n",
            "          Value: False\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: dict\n",
            "          Value: {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name=u'input_ids'), \b\b}\n",
            "        Argument #2\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #4\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #5\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #6\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #7\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #8\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #9\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #10\n",
            "          DType: bool\n",
            "          Value: False\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: dict\n",
            "          Value: {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name=u'inputs/input_ids'), \b\b}\n",
            "        Argument #2\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #4\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #5\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #6\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #7\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #8\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #9\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #10\n",
            "          DType: bool\n",
            "          Value: True\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: dict\n",
            "          Value: {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name=u'input_ids'), \b\b}\n",
            "        Argument #2\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #4\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #5\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #6\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #7\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #8\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #9\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #10\n",
            "          DType: bool\n",
            "          Value: True\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: dict\n",
            "          Value: {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name=u'input_ids'), \b\b}\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: dict\n",
            "          Value: {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name=u'input_ids'), \b\b}\n",
            "        Argument #2\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #4\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #5\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #6\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #7\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #8\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #9\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #10\n",
            "          DType: bool\n",
            "          Value: False\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: dict\n",
            "          Value: {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name=u'inputs/input_ids'), \b\b}\n",
            "        Argument #2\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #4\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #5\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #6\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #7\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #8\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #9\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #10\n",
            "          DType: bool\n",
            "          Value: True\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: dict\n",
            "          Value: {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name=u'input_ids'), \b\b}\n",
            "        Argument #2\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #4\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #5\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #6\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #7\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #8\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #9\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #10\n",
            "          DType: bool\n",
            "          Value: True\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: dict\n",
            "          Value: {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name=u'inputs/input_ids'), \b\b}\n",
            "        Argument #2\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #4\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #5\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #6\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #7\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #8\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #9\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "        Argument #10\n",
            "          DType: bool\n",
            "          Value: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8UgobTQaF4Y",
        "outputId": "b989d930-ec2b-4d7e-cf8c-bda9bb2346c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "bert_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "bert_model.summary()"
      ],
      "id": "M8UgobTQaF4Y",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  108310272 \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "=================================================================\n",
            "Total params: 108,311,810\n",
            "Trainable params: 108,311,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvBLfsWManpj",
        "outputId": "ad0bfdc5-7263-4151-d50e-9f78c4d2b4bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "bert_history = bert_model.fit(train_ds, epochs=3, validation_data=valid_ds)"
      ],
      "id": "IvBLfsWManpj",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1250/1250 [==============================] - 702s 549ms/step - loss: 0.4206 - accuracy: 0.7980 - val_loss: 0.2863 - val_accuracy: 0.8744\n",
            "Epoch 2/3\n",
            "1250/1250 [==============================] - 689s 551ms/step - loss: 0.2118 - accuracy: 0.9169 - val_loss: 0.2838 - val_accuracy: 0.8854\n",
            "Epoch 3/3\n",
            "1250/1250 [==============================] - 688s 550ms/step - loss: 0.1073 - accuracy: 0.9645 - val_loss: 0.3738 - val_accuracy: 0.8860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP-1mG26avH4"
      },
      "source": [
        "bert_test = [bert_encoder(r) for r,l in imdb_test]\n",
        "bert_tst_lbl = [l for r, l in imdb_test]\n",
        "bert_test2 = np.array(bert_test)\n",
        "\n",
        "bert_tst_lbl2 = tf.keras.utils.to_categorical (bert_tst_lbl,num_classes=2)\n",
        "\n",
        "ts_reviews, ts_segments, ts_masks = np.split(bert_test2, 3, axis=1)\n",
        "\n",
        "ts_reviews = ts_reviews.squeeze()\n",
        "ts_segments = ts_segments.squeeze()\n",
        "ts_masks = ts_masks.squeeze()\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((ts_reviews,\n",
        "                                              ts_masks, ts_segments, bert_tst_lbl2)).map(example_to_features).shuffle(100).batch(16)\n"
      ],
      "id": "pP-1mG26avH4",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdGecPefa_T1",
        "outputId": "4589f9c3-0364-4e46-bbca-f74447f9a265",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tempfile\n",
        "\n",
        "MODEL_DIR = tempfile.gettempdir()\n",
        "version = 1\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "print('export_path = {}\\n'.format(export_path))\n",
        "\n",
        "tf.keras.models.save_model(\n",
        "    bert_model,\n",
        "    export_path,\n",
        "    overwrite=True,\n",
        "    include_optimizer=True,\n",
        "    save_format=None,\n",
        "    signatures=None,\n",
        "    options=None\n",
        ")\n",
        "\n",
        "print('\\nSaved model:')\n",
        "!ls -l {export_path}"
      ],
      "id": "BdGecPefa_T1",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "export_path = /tmp/1\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, encoder_layer_call_and_return_conditional_losses, encoder_layer_call_fn, pooler_layer_call_and_return_conditional_losses while saving (showing 5 of 1065). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, encoder_layer_call_and_return_conditional_losses, encoder_layer_call_fn, pooler_layer_call_and_return_conditional_losses while saving (showing 5 of 1065). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/1/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Saved model:\n",
            "total 10060\n",
            "drwxr-xr-x 2 root root     4096 May 21 11:28 assets\n",
            "-rw-r--r-- 1 root root 10289460 May 21 11:28 saved_model.pb\n",
            "drwxr-xr-x 2 root root     4096 May 21 11:28 variables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDwbRcW9bGIB"
      },
      "source": [
        "### Custom model with BERT"
      ],
      "id": "dDwbRcW9bGIB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJZ1bfa0bFRO",
        "outputId": "27484821-a52f-47ea-e9d1-673ba80c07d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from transformers import TFBertModel\n",
        "bert_name = 'bert-base-cased'\n",
        "bert = TFBertModel.from_pretrained(bert_name)\n",
        "bert.summary()"
      ],
      "id": "rJZ1bfa0bFRO",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_tf_utils:Some weights of the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:transformers.modeling_tf_utils:All the weights of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  108310272 \n",
            "=================================================================\n",
            "Total params: 108,310,272\n",
            "Trainable params: 108,310,272\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7JItNPmbFNR"
      },
      "source": [
        "max_seq_len = 150\n",
        "inp_ids = tf.keras.layers.Input((max_seq_len,), dtype=tf.int64, name=\"input_ids\")\n",
        "att_mask = tf.keras.layers.Input((max_seq_len,), dtype=tf.int64, name=\"attention_mask\")\n",
        "seg_ids = tf.keras.layers.Input((max_seq_len,), dtype=tf.int64, name=\"token_type_ids\")"
      ],
      "id": "I7JItNPmbFNR",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXtISo3Wl7ff"
      },
      "source": [
        "inp_dict = {\"input_ids\": inp_ids,\n",
        " \"attention_mask\": att_mask,\n",
        " \"token_type_ids\": seg_ids}\n",
        "outputs = bert(inp_dict)\n",
        "\n",
        "'''\n",
        "  The first output has embeddings for each of the input tokens including the special\n",
        "  tokens [CLS] and [SEP]. The second output corresponds to the output of the [CLS]\n",
        "  token. This output will be used further in the mode\n",
        "'''\n",
        "\n",
        "bert.trainable = False # don't train BERT any more"
      ],
      "id": "FXtISo3Wl7ff",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clm9m7PFl7c1"
      },
      "source": [
        "x = tf.keras.layers.Dropout(0.2)(outputs[1])\n",
        "x = tf.keras.layers.Dense(200, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(2, activation='sigmoid')(x)\n",
        "\n",
        "custom_model = tf.keras.models.Model(inputs=inp_dict, outputs=x)"
      ],
      "id": "clm9m7PFl7c1",
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fuzOmRBl7WT"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "custom_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
      ],
      "id": "2fuzOmRBl7WT",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0PiZ5BlmqSH",
        "outputId": "e0a82fc0-3232-4b55-9235-73103a15ca5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "custom_model.summary()"
      ],
      "id": "b0PiZ5BlmqSH",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "attention_mask (InputLayer)     [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_ids (InputLayer)          [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "token_type_ids (InputLayer)     [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     ((None, 150, 768), ( 108310272   attention_mask[0][0]             \n",
            "                                                                 input_ids[0][0]                  \n",
            "                                                                 token_type_ids[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_79 (Dropout)            (None, 768)          0           tf_bert_model[2][1]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 200)          153800      dropout_79[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_80 (Dropout)            (None, 200)          0           dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 2)            402         dropout_80[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 108,464,474\n",
            "Trainable params: 154,202\n",
            "Non-trainable params: 108,310,272\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ryfXGbImsJB",
        "outputId": "6fc5c07f-c5e7-4fc2-ba52-ae65b96abb3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "custom_history = custom_model.fit(train_ds, epochs=3, validation_data=valid_ds)"
      ],
      "id": "7ryfXGbImsJB",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1250/1250 [==============================] - 304s 234ms/step - loss: 0.4274 - accuracy: 0.8135 - val_loss: 0.3646 - val_accuracy: 0.8358\n",
            "Epoch 2/3\n",
            "1250/1250 [==============================] - 290s 232ms/step - loss: 0.3703 - accuracy: 0.8407 - val_loss: 0.3582 - val_accuracy: 0.8376\n",
            "Epoch 3/3\n",
            "1250/1250 [==============================] - 291s 232ms/step - loss: 0.3632 - accuracy: 0.8410 - val_loss: 0.3549 - val_accuracy: 0.8378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "502JJoWxm3gF"
      },
      "source": [
        "custom_model.evaluate(test_ds)"
      ],
      "id": "502JJoWxm3gF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U2bfTvum686"
      },
      "source": [
        ""
      ],
      "id": "5U2bfTvum686",
      "execution_count": null,
      "outputs": []
    }
  ]
}