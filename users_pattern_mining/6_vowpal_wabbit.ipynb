{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUfouvutGoDs"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://habrastorage.org/web/677/8e1/337/6778e1337c3d4b159d7e99df94227cb2.jpg\"/>\n",
    "## Специализация \"Машинное обучение и анализ данных\"\n",
    "<center>Автор материала: программист-исследователь Mail.Ru Group, старший преподаватель Факультета Компьютерных Наук ВШЭ [Юрий Кашницкий](https://yorko.github.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8SC5R6jGoD6"
   },
   "source": [
    "# <center> Capstone проект №1 <br> Идентификация пользователей по посещенным веб-страницам\n",
    "<img src='http://i.istockimg.com/file_thumbview_approve/21546327/5/stock-illustration-21546327-identification-de-l-utilisateur.jpg'>\n",
    "\n",
    "# <center>Неделя 6.  Vowpal Wabbit\n",
    "\n",
    "На этой неделе мы познакомимся с популярной библиотекой Vowpal Wabbit и попробуем ее на данных по посещению сайтов.\n",
    "\n",
    "**План 6 недели:**\n",
    "- Часть 1. Статья по Vowpal Wabbit\n",
    "- Часть 2. Применение Vowpal Wabbit к данным по посещению сайтов\n",
    " - 2.1. Подготовка данных\n",
    " - 2.2. Валидация по отложенной выборке\n",
    " - 2.3. Валидация по тестовой выборке (Public Leaderboard)\n",
    "\n",
    "**В этой части проекта Вам могут быть полезны видеозаписи следующих лекций курса \"Обучение на размеченных данных\":**\n",
    "   - [Стохатический градиентный спуск](https://www.coursera.org/learn/supervised-learning/lecture/xRY50/stokhastichieskii-ghradiientnyi-spusk)\n",
    "   - [Линейные модели. `sklearn.linear_model`. Классификация](https://www.coursera.org/learn/supervised-learning/lecture/EBg9t/linieinyie-modieli-sklearn-linear-model-klassifikatsiia)\n",
    "   \n",
    "Также будет полезна [презентация](https://github.com/esokolov/ml-course-msu/blob/master/ML15/lecture-notes/Sem08_vw.pdf) лектора специализации Евгения Соколова. И, конечно же, [документация](https://github.com/JohnLangford/vowpal_wabbit/wiki) Vowpal Wabbit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0qtvQcWGoD8"
   },
   "source": [
    "### Задание\n",
    "1. Заполните код в этой тетрадке \n",
    "2. Если вы проходите специализацию Яндеса и МФТИ, пошлите файл с ответами в соответствующем Programming Assignment. <br> Если вы проходите курс ODS, выберите ответы в [веб-форме](https://docs.google.com/forms/d/1wteunpEhAt_9s-WBwxYphB6XpniXsAZiFSNuFNmvOdk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "111CZwUMGoD9"
   },
   "source": [
    "## Часть 1. Статья про Vowpal Wabbit\n",
    "Прочитайте [статью](https://habrahabr.ru/company/ods/blog/326418/) про Vowpal Wabbit на Хабре из серии открытого курса OpenDataScience по машинному обучению. Материал для этой статьи зародился из нашей специализации. Скачайте [тетрадку](https://github.com/Yorko/mlcourse_open/blob/master/jupyter_russian/topic08_sgd_hashing_vowpal_wabbit/topic8_sgd_hashing_vowpal_wabbit.ipynb), прилагаемую к статье, посмотрите код, изучите его, поменяйте, только так можно разобраться с Vowpal Wabbit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvi7xyWtGoD-"
   },
   "source": [
    "## Часть 2. Применение Vowpal Wabbit к данным по посещению сайтов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZ2wC-sOGoD_"
   },
   "source": [
    "### 2.1. Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "au7_XRckGoEA"
   },
   "source": [
    "**Далее посмотрим на Vowpal Wabbit в деле. Правда, в задаче нашего соревнования при бинарной классификации веб-сессий мы разницы не заметим – как по качеству, так и по скорости работы (хотя можете проверить), продемонстрируем всю резвость VW в задаче классификации на 400 классов. Исходные данные все те же самые, но выделено 400 пользователей, и решается задача их идентификации. Скачайте данные [отсюда](https://inclass.kaggle.com/c/identify-me-if-you-can4/data) – файлы `train_sessions_400users.csv` и `test_sessions_400users.csv`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4uDeKOvMHDsX",
    "outputId": "fc4b3ea9-dbe2-4fda-e34b-ce3b6ad73ff0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libvw0\n",
      "Suggested packages:\n",
      "  vowpal-wabbit-doc\n",
      "The following NEW packages will be installed:\n",
      "  libvw0 vowpal-wabbit\n",
      "0 upgraded, 2 newly installed, 0 to remove and 13 not upgraded.\n",
      "Need to get 797 kB of archives.\n",
      "After this operation, 3,034 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libvw0 amd64 8.5.0.dfsg1-1 [748 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 vowpal-wabbit amd64 8.5.0.dfsg1-1 [49.1 kB]\n",
      "Fetched 797 kB in 2s (362 kB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package libvw0.\n",
      "(Reading database ... 146374 files and directories currently installed.)\n",
      "Preparing to unpack .../libvw0_8.5.0.dfsg1-1_amd64.deb ...\n",
      "Unpacking libvw0 (8.5.0.dfsg1-1) ...\n",
      "Selecting previously unselected package vowpal-wabbit.\n",
      "Preparing to unpack .../vowpal-wabbit_8.5.0.dfsg1-1_amd64.deb ...\n",
      "Unpacking vowpal-wabbit (8.5.0.dfsg1-1) ...\n",
      "Setting up libvw0 (8.5.0.dfsg1-1) ...\n",
      "Setting up vowpal-wabbit (8.5.0.dfsg1-1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install vowpal-wabbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dvsj_WrtJgHE",
    "outputId": "3c85611c-7cd7-49a0-ec9c-da77dfd4759a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = \n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "8uCbyAYuGoEA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rJW0Os5J_A3",
    "outputId": "2e268690-b4b3-4fa8-c914-999c6414eee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Dnr618ngGoED"
   },
   "outputs": [],
   "source": [
    "# Поменяйте на свой путь к данным\n",
    "PATH_TO_DATA = 'drive/My Drive/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LkP5A7xGoED"
   },
   "source": [
    "**Загрузим обучающую и тестовую выборки. Можете заметить, что тестовые сессии здесь по времени четко отделены от сессий в обучающей выборке. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "eIBSYmjTGoEE"
   },
   "outputs": [],
   "source": [
    "train_df_400 = pd.read_csv(os.path.join(PATH_TO_DATA,'train_sessions_400users.csv'),\n",
    "                           index_col='session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "jELcLTMWGoEE"
   },
   "outputs": [],
   "source": [
    "test_df_400 = pd.read_csv(os.path.join(PATH_TO_DATA,'test_sessions_400users.csv'), \n",
    "                           index_col='session_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2ckFFhsGoEH"
   },
   "source": [
    "**Видим, что в обучающей выборке 182793 сессий, в тестовой – 46473, и сессии действительно принадлежат 400 различным пользователям.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5UVCEnUGoEI",
    "outputId": "aaa177ca-096f-4218-9a95-502a3858cf03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((182793, 21), (46473, 20), 400)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_400.shape, test_df_400.shape, train_df_400['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSjUmjdXGoEJ"
   },
   "source": [
    "**Vowpal Wabbit любит, чтоб метки классов были распределены от 1 до K, где K – число классов в задаче классификации (в нашем случае – 400). Поэтому придется применить `LabelEncoder`, да еще и +1 потом добавить (`LabelEncoder` переводит метки в диапозон от 0 до K-1). Потом надо будет применить обратное преобразование.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "K4VK9sXtGoEJ"
   },
   "outputs": [],
   "source": [
    "y = train_df_400['user_id']\n",
    "class_encoder = LabelEncoder()\n",
    "y_for_vw = class_encoder.fit_transform(y) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Oqo_VCBGoEK"
   },
   "source": [
    "**Далее будем сравнивать VW с SGDClassifier и с логистической регрессией. Всем моделям этим нужна предобработка входных данных. Подготовьте для sklearn-моделей разреженные матрицы, как мы это делали в 5 части:**\n",
    "- объедините обучающиую и тестовую выборки\n",
    "- выберите только сайты (признаки от 'site1' до 'site10')\n",
    "- замените пропуски на нули (сайты у нас нумеровались с 0)\n",
    "- переведите в разреженный формат `csr_matrix`\n",
    "- разбейте обратно на обучающую и тестовую части"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "9xz6qqxNGoEK"
   },
   "outputs": [],
   "source": [
    "sites = ['site' + str(i) for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "e0oPQLOjGoEL"
   },
   "outputs": [],
   "source": [
    "def dropcols_coo(C, idx_to_drop):\n",
    "    idx_to_drop = np.unique(idx_to_drop)\n",
    "    keep = ~np.in1d(C.col, idx_to_drop)\n",
    "    C.data, C.row, C.col = C.data[keep], C.row[keep], C.col[keep]\n",
    "    C.col -= idx_to_drop.searchsorted(C.col)    # decrement column indices\n",
    "    C._shape = (C.shape[0], C.shape[1] - len(idx_to_drop))\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "WFn2pTmBGoEL"
   },
   "outputs": [],
   "source": [
    "def transform_to_csr_matrix(arr):\n",
    "    rows = []\n",
    "    columns = []\n",
    "    data = []\n",
    "    for i in range(arr.shape[0]):\n",
    "        # Create dictionary {site: number of visits per session}\n",
    "        unique, counts = np.unique(arr[i], return_counts=True)\n",
    "        dic = dict(zip(unique, counts))\n",
    "        rows.extend([i]*len(dic.keys()))\n",
    "        columns.extend(dic.keys())\n",
    "        data.extend(dic.values())\n",
    "    \n",
    "    # Sparse coo matrix\n",
    "    arr_new_coo = coo_matrix((data, (rows, columns)))\n",
    "    \n",
    "    # Drop column with \"zero\" site and transform to csr\n",
    "    return dropcols_coo(arr_new_coo, 0).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "OnaJ1eD9GoEM"
   },
   "outputs": [],
   "source": [
    "train_test_df = pd.concat([train_df_400, test_df_400])\n",
    "train_test_df_sites = train_test_df[sites].fillna(0).astype('int')\n",
    "train_test_sparse = transform_to_csr_matrix(train_test_df_sites.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "rEA0LrwcGoEM"
   },
   "outputs": [],
   "source": [
    "X_train_sparse = train_test_sparse[:train_df_400.shape[0]]\n",
    "X_test_sparse = train_test_sparse[train_df_400.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZXRK9RLGoEN"
   },
   "source": [
    "### 2.2. Валидация по отложенной выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnLRFDISGoEN"
   },
   "source": [
    "**Выделим обучающую (70%) и отложенную (30%) части исходной обучающей выборки. Данные не перемешиваем, учитываем, что сессии отсортированы по времени.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "K5w07h-kGoEO"
   },
   "outputs": [],
   "source": [
    "train_df = train_df_400[sites].fillna(0).astype(np.int32)\n",
    "test_df = test_df_400[sites].fillna(0).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "EHt-ECjLGoEO"
   },
   "outputs": [],
   "source": [
    "train_share = int(.7 * train_df_400.shape[0])\n",
    "train_df_part = train_df_400[sites].iloc[:train_share, :]\n",
    "valid_df = train_df_400[sites].iloc[train_share:, :]\n",
    "X_train_part_sparse = X_train_sparse[:train_share, :]\n",
    "X_valid_sparse = X_train_sparse[train_share:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "OXLOgm0wGoEP"
   },
   "outputs": [],
   "source": [
    "y_train_part = y[:train_share]\n",
    "y_valid = y[train_share:]\n",
    "y_train_part_for_vw = y_for_vw[:train_share]\n",
    "y_valid_for_vw = y_for_vw[train_share:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrIj6SdLGoEP"
   },
   "source": [
    "**Реализуйте функцию, `arrays_to_vw`, переводящую обучающую выборку в формат Vowpal Wabbit.**\n",
    "\n",
    "Вход:\n",
    " - X – матрица `NumPy` (обучающая выборка)\n",
    " - y (необяз.) - вектор ответов (`NumPy`). Необязателен, поскольку тестовую матрицу будем обрабатывать этой же функцией\n",
    " - train – флаг, True в случае обучающей выборки, False – в случае тестовой выборки\n",
    " - out_file – путь к файлу .vw, в который будет произведена запись\n",
    " \n",
    "Детали:\n",
    "- надо пройтись по всем строкам матрицы `X` и записать через пробел все значения, предварительно добавив вперед нужную метку класса из вектора `y` и знак-разделитель `|`\n",
    "- в тестовой выборке на месте меток целевого класса можно писать произвольные, допустим, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "fgm3JTKUGoEQ"
   },
   "outputs": [],
   "source": [
    "def arrays_to_vw(X, y=None, train=True, out_file='tmp.vw'):\n",
    "    with open(os.path.join(PATH_TO_DATA, out_file), 'w') as out_vw:\n",
    "        for i, row in enumerate(np.nditer(X, flags=['external_loop'], order='C')):\n",
    "            arr_str = ' '.join(list(map(str, row)))\n",
    "            if y is None:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = y[i]\n",
    "            vw_str = '{} | {}'.format(label, arr_str)\n",
    "            out_vw.write(vw_str + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Evb0kgtLGoEQ"
   },
   "source": [
    "**Примените написанную функцию к части обучащей выборки `(train_df_part, y_train_part_for_vw)`, к отложенной выборке `(valid_df, y_valid_for_vw)`, ко всей обучающей выборке и ко всей тестовой выборке. Обратите внимание, что на вход наш метод принимает именно матрицы и вектора `NumPy`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y2BUoZ5uGoER",
    "outputId": "60ea7dfe-7e4e-4c21-aa21-2030d12e49de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.26 s, sys: 31.6 ms, total: 3.29 s\n",
      "Wall time: 3.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "arrays_to_vw(train_df_part.values, y_train_part_for_vw, out_file='train_part.vw')\n",
    "arrays_to_vw(valid_df.values, y_valid_for_vw, out_file='valid.vw')\n",
    "arrays_to_vw(train_df.values, y_for_vw, out_file='train.vw')\n",
    "arrays_to_vw(test_df.values, out_file='test.vw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WAFd19HGoES"
   },
   "source": [
    "**Обучите модель Vowpal Wabbitна выборке `train_part.vw`. Укажите, что решается задача классификации с 400 классами (`--oaa`), сделайте 3 прохода по выборке (`--passes`). Задайте некоторый кэш-файл (`--cache_file`, можно просто указать флаг `-c`), так VW будет быстрее делать все следующие после первого проходы по выборке (прошлый кэш-файл удаляется с помощью аргумента `-k`). Также укажите значение параметра `b`=26. Это число бит, используемых для хэширования, в данном случае нужно больше, чем 18 по умолчанию. Наконец, укажите `random_seed`=17. Остальные параметры пока не меняйте, далее уже в свободном режиме соревнования можете попробовать другие функции потерь.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "_pZ5a1t3GoES"
   },
   "outputs": [],
   "source": [
    "train_part_vw = os.path.join(PATH_TO_DATA, 'train_part.vw')\n",
    "valid_vw = os.path.join(PATH_TO_DATA, 'valid.vw')\n",
    "train_vw = os.path.join(PATH_TO_DATA, 'train.vw')\n",
    "test_vw = os.path.join(PATH_TO_DATA, 'test.vw')\n",
    "model = os.path.join(PATH_TO_DATA, 'vw_model.vw')\n",
    "pred = os.path.join(PATH_TO_DATA, 'vw_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AeSv6teLGoEV",
    "outputId": "791c425f-86c0-4e4d-b5f2-c9228f919f86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 1073741824 bytes == 0x556015b60000 @  0x7fc804af6001 0x7fc804692b5f 0x7fc8046a0a21 0x7fc804743e00 0x7fc804731be3 0x7fc804739395 0x7fc804739c44 0x556013f15237 0x556013f14a8b 0x7fc803cb1bf7 0x556013f1505a\n",
      "CPU times: user 119 ms, sys: 30.6 ms, total: 149 ms\n",
      "Wall time: 32.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw -d drive/MyDrive/data/train_part.vw \\\n",
    "--passes 3 \\\n",
    "--oaa 400 \\\n",
    "-c \\\n",
    "-k \\\n",
    "-b 26 \\\n",
    "--random_seed 17 \\\n",
    "-f data/model.vw \\\n",
    "--quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SwZIjn5aGoEV"
   },
   "source": [
    "**Запишите прогнозы на выборке *valid.vw* в *vw_valid_pred.csv*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_RsxVZf2GoEV",
    "outputId": "2b5ea04f-80ca-410c-affe-b6810cc49a54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.91 ms, sys: 15.7 ms, total: 22.7 ms\n",
      "Wall time: 1.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw -i data/model.vw -t -d drive/MyDrive/data/valid.vw \\\n",
    "-p vw_valid_pred.txt \\\n",
    "--quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Djt9CGuFGoEV"
   },
   "source": [
    "**Считайте прогнозы *kaggle_data/vw_valid_pred.csv*  из файла и посмотрите на долю правильных ответов на отложенной части.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBYoO_7lGoEW",
    "outputId": "81587503-e029-436e-cb7c-f18f2d7e488d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3427732594186513"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('vw_valid_pred.txt') as pred_file:\n",
    "    valid_prediction = [int(label) for label in pred_file.readlines()]\n",
    "    \n",
    "accuracy_score(y_valid_for_vw, valid_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqBBnK7EGoEW"
   },
   "source": [
    "**Теперь обучите `SGDClassifier` (3 прохода по выборке, логистическая функция потерь) и `LogisticRegression` на 70% разреженной обучающей выборки – `(X_train_part_sparse, y_train_part)`, сделайте прогноз для отложенной выборки `(X_valid_sparse, y_valid)` и посчитайте доли верных ответов. Логистическая регрессия будет обучаться не быстро (у меня – 4 минуты) – это нормально. Укажите везде `random_state`=17, `n_jobs`=-1. Для `SGDClassifier` также укажите `max_iter=3`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "oWszWmoNGoEW"
   },
   "outputs": [],
   "source": [
    "logit = LogisticRegression(random_state=17, n_jobs=-1)\n",
    "sgd_logit = SGDClassifier(loss='log', max_iter=3, random_state=17, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCvw2IwlGoEW",
    "outputId": "e099d245-5e00-4f5e-9ffd-3fc76cd1deeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.26 s, sys: 559 ms, total: 1.82 s\n",
      "Wall time: 11min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=-1, penalty='l2', random_state=17,\n",
       "                   solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logit.fit(X_train_part_sparse, y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eNnvgX0mGoEX",
    "outputId": "c2b0bb5e-2db7-4946-b89f-709f70ec6f84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 10s, sys: 16.9 s, total: 1min 27s\n",
      "Wall time: 44.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=3,\n",
       "              n_iter_no_change=5, n_jobs=-1, penalty='l2', power_t=0.5,\n",
       "              random_state=17, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sgd_logit.fit(X_train_part_sparse, y_train_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeqEgeq2GoEX"
   },
   "source": [
    "**<font color='red'>Вопрос 1. </font> Посчитайте долю правильных ответов на отложенной выборке для Vowpal Wabbit, округлите до 3 знаков после запятой.**\n",
    "\n",
    "**<font color='red'>Вопрос 2. </font> Посчитайте долю правильных ответов на отложенной выборке для SGD, округлите до 3 знаков после запятой.**\n",
    "\n",
    "**<font color='red'>Вопрос 3. </font> Посчитайте долю правильных ответов на отложенной выборке для логистической регрессии, округлите до 3 знаков после запятой.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "Xw8y3nYzGoEX"
   },
   "outputs": [],
   "source": [
    "vw_valid_acc = accuracy_score(y_valid_for_vw, valid_prediction)\n",
    "\n",
    "sgd_pred = sgd_logit.predict(X_valid_sparse)\n",
    "sgd_valid_acc = accuracy_score(y_valid, sgd_pred)\n",
    "logit_pred = logit.predict(X_valid_sparse)\n",
    "logit_valid_acc = accuracy_score(y_valid, logit_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "ZbO5bAP5GoEX"
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, file_address):\n",
    "    with open(file_address, 'w') as out_f:\n",
    "        out_f.write(str(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "73HYfOodGoEY"
   },
   "outputs": [],
   "source": [
    "write_answer_to_file(round(vw_valid_acc, 3), 'answer6_1.txt')\n",
    "write_answer_to_file(round(sgd_valid_acc, 3), 'answer6_2.txt')\n",
    "write_answer_to_file(round(logit_valid_acc, 3), 'answer6_3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFu0AhDTGoEY"
   },
   "source": [
    "### 2.3. Валидация по тестовой выборке (Public Leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ag1L_f5ZGoEY"
   },
   "source": [
    "**Обучите модель VW с теми же параметрами на всей обучающей выборке – *train.vw*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jfAeq65DGoEY"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "!vw -d data/train.vw \\\n",
    "--passes 3 \\\n",
    "--oaa 400 \\\n",
    "-c \\\n",
    "-k \\\n",
    "-b 26 \\\n",
    "--random_seed 17 \\\n",
    "-f data/model.vw \\\n",
    "--quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPHl20rVGoEZ"
   },
   "source": [
    "**Сделайте прогноз для тестовой выборки.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eiu6AE1rGoEZ"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "!vw -i data/model.vw -t -d data/test.vw \\\n",
    "-p vw_test_pred.txt \\\n",
    "--quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WlPXf6j4S9uc"
   },
   "outputs": [],
   "source": [
    "with open('vw_test_pred.txt') as pred_file:\n",
    "    vw_pred = np.array([int(label) for label in pred_file.readlines()])\n",
    "    \n",
    "vw_pred = class_encoder.inverse_transform(vw_pred - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qAZFpOVGoEZ"
   },
   "source": [
    "**Запишите прогноз в файл, примените обратное преобразование меток (был LabelEncoder и потом +1 в меткам) и отправьте решение на Kaggle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3UYSQz--GoEZ"
   },
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='user_id', index_label=\"session_id\"):\n",
    "    # turn predictions into data frame and save as csv file\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbL-mS0BGoEa"
   },
   "outputs": [],
   "source": [
    "write_to_submission_file(vw_pred, os.path.join(PATH_TO_DATA, 'vw_400_users.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJMIgKVKGoEa"
   },
   "source": [
    "**Сделайте то же самое для SGD и логистической регрессии. Тут уже ждать обучение логистической регрессии совсем скучно (заново запускать тетрадку вам не захочется), но давайте дождемся.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubHWuq_dGoEa"
   },
   "outputs": [],
   "source": [
    "logit = LogisticRegression(random_state=17, n_jobs=-1)\n",
    "sgd_logit = SGDClassifier(loss='log', max_iter=3, random_state=17, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4i3_sHZBTKwb"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "logit.fit(X_train_sparse, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_J-BQX3TLGd"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd_logit.fit(X_train_sparse, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E3y0gVBuTMn1"
   },
   "outputs": [],
   "source": [
    "logit_test_pred = logit.predict(X_test_sparse)\n",
    "sgd_logit_test_pred = sgd_logit.predict(X_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MmRzQD5GGoEb"
   },
   "outputs": [],
   "source": [
    "write_to_submission_file(logit_test_pred, \n",
    "                         os.path.join(PATH_TO_DATA, 'logit_400_users.csv'))\n",
    "write_to_submission_file(sgd_logit_test_pred, \n",
    "                         os.path.join(PATH_TO_DATA, 'sgd_400_users.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruQAzWjVGoEb"
   },
   "source": [
    "Посмотрим на доли правильных ответов на публичной части (public leaderboard) тестовой выборки [этого](https://inclass.kaggle.com/c/identify-me-if-you-can4) соревнования.\n",
    "\n",
    "**<font color='red'>Вопрос 4. </font> Какова доля правильных ответов на публичной части тестовой выборки (public leaderboard)  для Vowpal Wabbit?**\n",
    "\n",
    "**<font color='red'>Вопрос 5. </font> Какова доля правильных ответов на публичной части тестовой выборки (public leaderboard)  для SGD?**\n",
    "\n",
    "**<font color='red'>Вопрос 6. </font> Какова доля правильных ответов на публичной части тестовой выборки (public leaderboard)  для логистической регрессии?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFwN9W3VGoEb"
   },
   "outputs": [],
   "source": [
    "vw_lb_score = accuracy_score(y_valid_for_vw, valid_prediction)\n",
    "\n",
    "sgd_pred = sgd_logit.predict(X_valid_sparse)\n",
    "sgd_lb_score = accuracy_score(y_valid, sgd_pred)\n",
    "logit_pred = logit.predict(X_valid_sparse)\n",
    "logit_lb_score = accuracy_score(y_valid, logit_pred)\n",
    "\n",
    "write_answer_to_file(round(vw_lb_score, 3), 'answer6_4.txt')\n",
    "write_answer_to_file(round(sgd_lb_score, 3), 'answer6_5.txt')\n",
    "write_answer_to_file(round(logit_lb_score, 3), 'answer6_6.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBVcsiVxGoEb"
   },
   "source": [
    "**В заключение по заданию:**\n",
    "- Про соотношение качества классификации и скорости обучения VW, SGD и logit выводы предлагается сделать самостоятельно\n",
    "- Пожалуй, задача классификации на 400 классов (идентификация 400 пользователей) решается недостаточно хорошо при честном отделении по времени тестовой выборки от обучающей. Далее мы будем соревноваться в идентификации одного пользователя (Элис) – [вот](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2) соревнование, в котором предлагается поучаствовать. Не перепутайте! \n",
    "\n",
    "**Удачи!**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "6_vowpal_wabbit.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
